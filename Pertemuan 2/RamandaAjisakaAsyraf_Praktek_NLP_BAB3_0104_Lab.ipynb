{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RamandaAjisakaAsyraf_Praktek_NLP_BAB3_0104_Lab.ipynb","provenance":[],"collapsed_sections":["WSPf6pohiPIz","XBRhrzppj8XH","hXaTAOrslf3J","DknxM3TFoHi-","3z9MJ2YhrEuE","V2gTlRNsocBG","2niFsagVo3dD","T_gsVs-MqC6g","049WM2PNrMJ8","hdalNFp5q-df","mVnOV7Iir2t7","xp5GekzCuXPu","G7LsOM2FveFD","VYQV-fa_zYJD","O5gOsY800cta","AE2MS1KCEguM","mPG_cCMiGCjP","xKO6jQC9HWb-","SWZpdrwMIXRI","TYqhXI9FIi75"],"mount_file_id":"1P9-i-b36s5F4hVcMGeW2_5-WrFv-mmHC","authorship_tag":"ABX9TyMgDyO+0y/sJalHNxM7LVjl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Building Your NLP Vocabulary\n","\n","Nama  : Ramanda Ajisaka Asyraf\n","\n","NPM   : 20312067\n","\n","Kelas : IF Gab 1"],"metadata":{"id":"nGNEHtEbAMzu"}},{"cell_type":"markdown","source":["## Understanding Tokenization\n","\n","Tokenisasi digunakan untuk memisah kalimat menjadi satu kata, contohnya sebagai berikut:\n","1. \"Ramanda sedang belajar tokenisasi\"\n","2. Setelah diproses tokeniasi maka kalimat diatas akan berubah menjadi\n","\n"," ['Ramanda', 'sedang', 'belajar', 'tokenisasi']\n","4. untuk lebih jelasnya dapat dilihat pada contoh kodingan dibawah ini"],"metadata":{"id":"WSPf6pohiPIz"}},{"cell_type":"markdown","source":["### Exploring Tokenization"],"metadata":{"id":"XBRhrzppj8XH"}},{"cell_type":"code","source":["sentence = \"Ramanda sedang belajar tokenisasi\"\n","sentence.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKU0Dx_cj7RX","executionInfo":{"status":"ok","timestamp":1648777313175,"user_tz":-420,"elapsed":619,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"fdcfc9f7-0575-40af-ada0-ed59d7a6e049"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Ramanda', 'sedang', 'belajar', 'tokenisasi']"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["sentence = \"The capital of China is Beijing\"\n","sentence.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7MpXIawkkQJO","executionInfo":{"status":"ok","timestamp":1648777313175,"user_tz":-420,"elapsed":11,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"cc710e57-3166-410c-fa63-e9e5502ccf54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The', 'capital', 'of', 'China', 'is', 'Beijing']"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["sentnce = \"China's capital is Beijing\"\n","sentence.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJ2jIBJBkY21","executionInfo":{"status":"ok","timestamp":1648777313175,"user_tz":-420,"elapsed":10,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"49b779c1-2ce5-49ff-ecdd-33ea88027487"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The', 'capital', 'of', 'China', 'is', 'Beijing']"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["sentence = \"Beijing is where we'll go\"\n","sentence.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbbrr5ACkq0M","executionInfo":{"status":"ok","timestamp":1648777313176,"user_tz":-420,"elapsed":11,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"9b051c7d-649c-4fa3-ba55-e5258da7c926"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Beijing', 'is', 'where', \"we'll\", 'go']"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["sentence = \"I'm going to travel to Beijing\"\n","sentence.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HT4dLiMMkuR8","executionInfo":{"status":"ok","timestamp":1648777313176,"user_tz":-420,"elapsed":10,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"9a5059d4-e768-4b49-bb2d-14bb00f1df41"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"I'm\", 'going', 'to', 'travel', 'to', 'Beijing']"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["sentence = \"Most of the times umm I travel\"\n","sentence.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qyGcwPWzkw2m","executionInfo":{"status":"ok","timestamp":1648777313177,"user_tz":-420,"elapsed":11,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"5390806f-70df-48dd-908a-5e774833c02c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Most', 'of', 'the', 'times', 'umm', 'I', 'travel']"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["sentence = \"Let's travel to Hong Kong from Beijing\"\n","sentence.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zOL3sV7vkyYE","executionInfo":{"status":"ok","timestamp":1648777313177,"user_tz":-420,"elapsed":10,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"2ce0b0fa-b409-4462-e537-e7d61b537b9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Let's\", 'travel', 'to', 'Hong', 'Kong', 'from', 'Beijing']"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["sentence = \"A friend is pursuing his M.S from Beijing\"\n","sentence.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IV4WzbH7kz0E","executionInfo":{"status":"ok","timestamp":1648777313177,"user_tz":-420,"elapsed":9,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"23c5fd81-d9cf-43ab-cacf-4d4d394b62ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A', 'friend', 'is', 'pursuing', 'his', 'M.S', 'from', 'Beijing']"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["sentence = \"Beijing is a cool place!!! :-P <3 #Awesome\"\n","sentence.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xML966gMk4ts","executionInfo":{"status":"ok","timestamp":1648777313178,"user_tz":-420,"elapsed":10,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"decb2934-d6e4-4e6b-a998-b0e0d224479b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Beijing', 'is', 'a', 'cool', 'place!!!', ':-P', '<3', '#Awesome']"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","source":["### Regexp Tokenizer\n","\n","regex dapat dipadukan untuk mentokenisasi sebuah kalimat. contoh penggunaanya dapat dilihat pada baris kode dibawah ini."],"metadata":{"id":"hXaTAOrslf3J"}},{"cell_type":"code","source":["from nltk.tokenize import RegexpTokenizer\n","s = \"A Rolex watch costs in the range of $3000.0 - $8000.0 in USA.\"\n","tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n","tokenizer.tokenize(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0K6Z7EGNllvP","executionInfo":{"status":"ok","timestamp":1648777313178,"user_tz":-420,"elapsed":9,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"19f8b542-b061-47d8-99e9-6ef36317570b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A',\n"," 'Rolex',\n"," 'watch',\n"," 'costs',\n"," 'in',\n"," 'the',\n"," 'range',\n"," 'of',\n"," '$3000.0',\n"," '-',\n"," '$8000.0',\n"," 'in',\n"," 'USA',\n"," '.']"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["### Blankline Tokenizer\n","\n","tokenisasi menggunakan blankline(\\n\\n)"],"metadata":{"id":"PPbLe1DBlskf"}},{"cell_type":"code","source":["from nltk.tokenize import BlanklineTokenizer\n","s = \"A Rolex watch costs in the range of $3000.0 - $8000.0 in USA.\\n\\n I want a book as well\"\n","tokenizer = BlanklineTokenizer()\n","tokenizer.tokenize(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdQjK7GVly7f","executionInfo":{"status":"ok","timestamp":1648777313178,"user_tz":-420,"elapsed":9,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"a09ba6dc-e08a-48e0-84c9-8f9aeeaed89c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A Rolex watch costs in the range of $3000.0 - $8000.0 in USA.',\n"," 'I want a book as well']"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["### WordPunct Tokenizer\n","\n","tokenisasi dengan menggunakan WordPunctTokenizer"],"metadata":{"id":"ttiKrn8Sl8gH"}},{"cell_type":"code","source":["from nltk.tokenize import WordPunctTokenizer\n","s = \"A Rolex watch costs in the range of $3000.0 - $8000.0 in USA.\\n I want a book as well\"\n","tokenizer = WordPunctTokenizer()\n","tokenizer.tokenize(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vC3BABXXl9_H","executionInfo":{"status":"ok","timestamp":1648777313178,"user_tz":-420,"elapsed":8,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"0dd73378-3400-4272-f3d9-3982ff69fb94"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A',\n"," 'Rolex',\n"," 'watch',\n"," 'costs',\n"," 'in',\n"," 'the',\n"," 'range',\n"," 'of',\n"," '$',\n"," '3000',\n"," '.',\n"," '0',\n"," '-',\n"," '$',\n"," '8000',\n"," '.',\n"," '0',\n"," 'in',\n"," 'USA',\n"," '.',\n"," 'I',\n"," 'want',\n"," 'a',\n"," 'book',\n"," 'as',\n"," 'well']"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["### TreebankWord Tokenizer\n","\n","tokensiasi dengan menggunakan TreebankWordTokenizer"],"metadata":{"id":"stsnqeAqmXld"}},{"cell_type":"code","source":["from nltk.tokenize import TreebankWordTokenizer\n","s = \"I'm going to buy a Rolex watch which doesn't cost more than $3000.0\"\n","tokenizer = TreebankWordTokenizer()\n","tokenizer.tokenize(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gwo4AKTzmFAe","executionInfo":{"status":"ok","timestamp":1648777313179,"user_tz":-420,"elapsed":9,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"f4777c27-ba5e-4b9f-d0bc-b4dd6a08511b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['I',\n"," \"'m\",\n"," 'going',\n"," 'to',\n"," 'buy',\n"," 'a',\n"," 'Rolex',\n"," 'watch',\n"," 'which',\n"," 'does',\n"," \"n't\",\n"," 'cost',\n"," 'more',\n"," 'than',\n"," '$',\n"," '3000.0']"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["### Tweet Tokenizer\n","\n","tokeniasi yang khusus digunakan untuk media sosial yang dimana terdapat emoticon, hastag dan lainnya."],"metadata":{"id":"5PjfDGCAng15"}},{"cell_type":"code","source":["from nltk.tokenize import TweetTokenizer\n","s = \"@amankedia I'm going to buy a Rolexxxxxxxx watch!!! :-D #happiness #rolex <3\"\n","tokenizer = TweetTokenizer()\n","tokenizer.tokenize(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6AmjDyunnkZh","executionInfo":{"status":"ok","timestamp":1648777313179,"user_tz":-420,"elapsed":8,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"5527c147-211b-4ddc-ff04-7ad68052caad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['@amankedia',\n"," \"I'm\",\n"," 'going',\n"," 'to',\n"," 'buy',\n"," 'a',\n"," 'Rolexxxxxxxx',\n"," 'watch',\n"," '!',\n"," '!',\n"," '!',\n"," ':-D',\n"," '#happiness',\n"," '#rolex',\n"," '<3']"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["from nltk.tokenize import TweetTokenizer\n","s = \"@amankedia I'm going to buy a Rolexxxxxxxx watch!!! :-D #happiness #rolex <3\"\n","tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n","tokenizer.tokenize(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ayDz1Lg9n7FO","executionInfo":{"status":"ok","timestamp":1648777313179,"user_tz":-420,"elapsed":8,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"3f8960f2-eab5-4281-f495-4a8fca0a2488"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"I'm\",\n"," 'going',\n"," 'to',\n"," 'buy',\n"," 'a',\n"," 'Rolexxx',\n"," 'watch',\n"," '!',\n"," '!',\n"," '!',\n"," ':-D',\n"," '#happiness',\n"," '#rolex',\n"," '<3']"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["## Stemming, Lemmatization, Stopword Removal, Case-Folding, N-grams and HTML tags"],"metadata":{"id":"DknxM3TFoHi-"}},{"cell_type":"markdown","source":["### Stemming\n","\n","stemming merupakan cara untuk menghapus bentuk infleksi dari sebuah kata dan membawanya ke bentuk dasar\n","disebut batang. Sebagai contohnya kata \"memakan\" jika distemming akan menjadi \"makan\". Untuk lebih jelasnya bisa dilihat pada contoh program dibawah ini dengan beberapa cara stemming."],"metadata":{"id":"3z9MJ2YhrEuE"}},{"cell_type":"markdown","source":["#### Exploring Tokenization"],"metadata":{"id":"V2gTlRNsocBG"}},{"cell_type":"code","source":["import nltk"],"metadata":{"id":"_3uycg12ojg1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plurals = ['caresses', 'flies', 'dies', 'mules', 'died', 'agreed', 'owned', 'humbled', 'sized', 'meeting', 'stating',\n","           'siezing', 'itemization', 'traditional', 'reference', 'colonizer', 'plotted', 'having', 'generously']"],"metadata":{"id":"Jcn3DRXxombl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Porter Stemmer\n","\n","Porter Stemmer hanya dapat dilakukan pada string saja."],"metadata":{"id":"2niFsagVo3dD"}},{"cell_type":"code","source":["from nltk.stem.porter import PorterStemmer \n","stemmer = PorterStemmer()\n","singles = [stemmer.stem(plural) for plural in plurals]\n","print(' '.join(singles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPJm1t0Go7I8","executionInfo":{"status":"ok","timestamp":1648774860638,"user_tz":-420,"elapsed":378,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"4d461612-922e-48c2-c6e0-81a3c087504a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["caress fli die mule die agre own humbl size meet state siez item tradit refer colon plot have gener\n"]}]},{"cell_type":"markdown","source":["#### Snowball Stemmer\n","\n","Untuk Snowball Stmmer dapat digunakan baik itu string ataupun unicode data. selain itu dia juga memiliki opsi fungsi untuk mengabaikan stopwords"],"metadata":{"id":"T_gsVs-MqC6g"}},{"cell_type":"code","source":["from nltk.stem.snowball import SnowballStemmer\n","print(SnowballStemmer.languages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7kd8mJRqdy3","executionInfo":{"status":"ok","timestamp":1648775260814,"user_tz":-420,"elapsed":372,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"a806d9a9-b296-4526-870c-ce6a29c5d360"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"]}]},{"cell_type":"markdown","source":["### Lemmatization\n","\n","Tidak seperti stemming, di mana beberapa karakter dihilangkan dari kata-kata menggunakan metode kasar, lemmatization adalah proses dimana konteks digunakan untuk mengubah kata menjadi bentuk dasarnya yang bermakna."],"metadata":{"id":"049WM2PNrMJ8"}},{"cell_type":"markdown","source":["#### Wordnet Lemmatizer\n","\n","WordNet adalah basis data leksikal bahasa Inggris yang tersedia secara bebas dan untuk umum"],"metadata":{"id":"hdalNFp5q-df"}},{"cell_type":"code","source":["nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6zWJ0-GAroCE","executionInfo":{"status":"ok","timestamp":1648775570529,"user_tz":-420,"elapsed":421,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"41f81665-3b05-433a-e31a-19ef050530ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","s = \"We are putting in efforts to enhance our understanding of Lemmatization\"\n","token_list = s.split()\n","print(\"The tokens are: \", token_list)\n","lemmatized_output = ' '.join([lemmatizer.lemmatize(token) for token in token_list])\n","print(\"The lemmatized output is: \", lemmatized_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDSuT-F6rt1D","executionInfo":{"status":"ok","timestamp":1648775588985,"user_tz":-420,"elapsed":1871,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"503b17cf-82c2-49e9-8f7a-cfc47c4a6149"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The tokens are:  ['We', 'are', 'putting', 'in', 'efforts', 'to', 'enhance', 'our', 'understanding', 'of', 'Lemmatization']\n","The lemmatized output is:  We are putting in effort to enhance our understanding of Lemmatization\n"]}]},{"cell_type":"markdown","source":["#### POS Tagging\n","\n","Dapat dilihat pada output diatas WordNet lemmatizer belum cukup. Kita perlu malkukan POS tagging pada setiap kata, untungnya library nltk memiliki metode yang dapat kita gunakan."],"metadata":{"id":"mVnOV7Iir2t7"}},{"cell_type":"code","source":["nltk.download('averaged_perceptron_tagger')\n","pos_tags = nltk.pos_tag(token_list)\n","pos_tags"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uytvAxE4tF7v","executionInfo":{"status":"ok","timestamp":1648775949567,"user_tz":-420,"elapsed":418,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"78ce1b2a-f6cd-4b74-a84d-f2b1946233a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["[('We', 'PRP'),\n"," ('are', 'VBP'),\n"," ('putting', 'VBG'),\n"," ('in', 'IN'),\n"," ('efforts', 'NNS'),\n"," ('to', 'TO'),\n"," ('enhance', 'VB'),\n"," ('our', 'PRP$'),\n"," ('understanding', 'NN'),\n"," ('of', 'IN'),\n"," ('Lemmatization', 'NN')]"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["Seperti yang dapat dilihat pada output diatas dikembalikan sebuah tuple. Kita perlu mengkonverisnya agar dapar diolah oleh lemmatizer."],"metadata":{"id":"i0AjA-imtPLA"}},{"cell_type":"code","source":["from nltk.corpus import wordnet\n","\n","## Metode umum yang sering digunakan untuk melakukan mapping\n","\n","def get_part_of_speech_tags(token):\n","    \n","    \"\"\"Maps POS tags to first character lemmatize() accepts.\n","    We are focussing on Verbs, Nouns, Adjectives and Adverbs here.\"\"\"\n","\n","    tag_dict = {\"J\": wordnet.ADJ,\n","                \"N\": wordnet.NOUN,\n","                \"V\": wordnet.VERB,\n","                \"R\": wordnet.ADV}\n","    \n","    tag = nltk.pos_tag([token])[0][1][0].upper()\n","    \n","    return tag_dict.get(tag, wordnet.NOUN)"],"metadata":{"id":"6AJ-E-SItjSn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Untuk hasil akhirnya setelah melakukan mapping dapat kalian lihat pada output coding dibawah ini dan bandingkan pada output pertama tadi jelas berbeda dan tidak menghilangkan makna dari kalimat tersebut.\n","\n","1. are to be\n","2. putting to put\n","3. efforts to effort\n","4. understanding to understand"],"metadata":{"id":"keWf8JU4t6pW"}},{"cell_type":"code","source":["lemmatized_output_with_POS_information = [lemmatizer.lemmatize(token, get_part_of_speech_tags(token)) for token in token_list]\n","print(' '.join(lemmatized_output_with_POS_information))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X9kbJeRot1PX","executionInfo":{"status":"ok","timestamp":1648776147586,"user_tz":-420,"elapsed":371,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"f7d89a25-c489-40ee-9684-47e0497cbd53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We be put in effort to enhance our understand of Lemmatization\n"]}]},{"cell_type":"markdown","source":["#### Lemmatization vs Stemming\n","\n","Dapat kalian lihat pada output dibawah ini jika menggunakan WordNet lemmatizer lebih masuk akal dan secara sadar konteks dari tokennya dalam bentuk dasar. Sedangkan stemmer mencoba untuk memotong afiks dari token."],"metadata":{"id":"xp5GekzCuXPu"}},{"cell_type":"code","source":["stemmer2 = SnowballStemmer(language='english')\n","stemmed_sentence = [stemmer2.stem(token) for token in token_list]\n","print(' '.join(stemmed_sentence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RohYHkYNudsU","executionInfo":{"status":"ok","timestamp":1648776558132,"user_tz":-420,"elapsed":411,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"2ea6ff57-60a0-49c5-b26d-e47155b23ac2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["we are put in effort to enhanc our understand of lemmat\n"]}]},{"cell_type":"markdown","source":["#### spaCy Lemmatizer\n","\n","Dapat mengurai teks dan mencari properti dari teks tersebut seperti POS tag. "],"metadata":{"id":"G7LsOM2FveFD"}},{"cell_type":"code","source":["import spacy\n","nlp = spacy.load('en')\n","doc = nlp(\"We are putting in efforts to enhance our understanding of Lemmatization\")\n","\" \".join([token.lemma_ for token in doc])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"piWu17mkvgn6","executionInfo":{"status":"ok","timestamp":1648776676426,"user_tz":-420,"elapsed":1418,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"73b5153e-780c-4aa2-807b-e469f0963bc2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'-PRON- be put in effort to enhance -PRON- understanding of lemmatization'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["### Stopwords\n","\n","Kalian dapat melihat tehnik penghapusan stopword secara lebih rinci pada contoh dibawah ini."],"metadata":{"id":"VYQV-fa_zYJD"}},{"cell_type":"code","source":["nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stop = set(stopwords.words('english'))\n","\", \".join(stop)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"1mFYCEKhzpFj","executionInfo":{"status":"ok","timestamp":1648777665494,"user_tz":-420,"elapsed":406,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"aea7ef14-f5c0-4d58-ddfc-af2ab07cf4bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["\"below, weren, out, until, our, won, down, there, no, me, hadn't, ourselves, at, once, just, before, all, didn't, an, won't, by, doesn't, should, only, other, doesn, shouldn't, y, needn, aren't, during, you've, aren, didn, hasn't, had, now, into, of, she's, too, you'll, haven, be, a, them, from, themselves, you, few, mustn't, over, yourselves, have, off, where, about, whom, after, such, couldn't, hadn, the, yourself, do, wouldn, ours, him, any, ve, yours, they, his, nor, was, under, their, don, through, against, on, again, being, has, is, wasn, most, between, mightn, isn't, were, wasn't, having, you're, herself, d, as, while, isn, shan't, been, myself, she, here, he, wouldn't, which, and, same, or, hasn, how, will, you'd, some, those, weren't, ain, it's, if, further, o, very, up, hers, to, ll, this, why, more, i, re, so, it, than, each, my, that'll, can, mustn, that, when, himself, couldn, am, did, because, with, these, in, both, should've, s, for, mightn't, shan, but, ma, does, needn't, haven't, t, who, its, theirs, don't, then, her, own, your, m, shouldn, above, we, itself, doing, are, not, what\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n","\n","stop = set(stopwords.words('english'))\n","\n","sentence = \"how are we putting in efforts to enhance our understanding of Lemmatization\"\n","\n","for word in wh_words:\n","    stop.remove(word)\n","\n","sentence_after_stopword_removal = [token for token in sentence.split() if token not in stop]\n","\" \".join(sentence_after_stopword_removal)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"krYChGTC0UlS","executionInfo":{"status":"ok","timestamp":1648777844197,"user_tz":-420,"elapsed":370,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"2f7584e2-61d4-49c9-e7e3-fdf146bccad9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'how putting efforts enhance understanding Lemmatization'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["### Case Folding\n","\n","\n","Strategi lain yang membantu normalisasi disebut case folding. Sebagai bagian dari kasus\n","lipat, semua huruf dalam korpus teks diubah menjadi huruf kecil."],"metadata":{"id":"O5gOsY800cta"}},{"cell_type":"code","source":["s = \"We are putting in efforts to enhance our understanding of Lemmatization\"\n","s = s.lower()\n","s"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"iNidUudN0mKy","executionInfo":{"status":"ok","timestamp":1648777915308,"user_tz":-420,"elapsed":404,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"d14215c2-fe1c-42f5-81e6-f9e8a315ebb2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'we are putting in efforts to enhance our understanding of lemmatization'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["### N-grams\n","\n","kita dapat melakukan tokenisasi dengan 2 kata atau lebih. untuk contohnya dapat dilahat sebagai berikut"],"metadata":{"id":"AE2MS1KCEguM"}},{"cell_type":"markdown","source":["#### Bigrams"],"metadata":{"id":"Oo2MK_dMFOkD"}},{"cell_type":"code","source":["from nltk.util import ngrams\n","s = \"Natural Language Processing is the way to go\"\n","tokens = s.split()\n","bigrams = list(ngrams(tokens, 2))\n","[\" \".join(token) for token in bigrams]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qkTDexQtFFu1","executionInfo":{"status":"ok","timestamp":1648950038350,"user_tz":-420,"elapsed":1377,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"ab7b7f7e-57e1-43ed-8cd6-60b747829859"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Natural Language',\n"," 'Language Processing',\n"," 'Processing is',\n"," 'is the',\n"," 'the way',\n"," 'way to',\n"," 'to go']"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["#### Trigrams"],"metadata":{"id":"yzw7IrK3FSsN"}},{"cell_type":"code","source":["s = \"Natural Language Processing is the way to go\"\n","tokens = s.split()\n","trigrams = list(ngrams(tokens, 3))\n","[\" \".join(token) for token in trigrams]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3VBjBzeGFVw2","executionInfo":{"status":"ok","timestamp":1648950102042,"user_tz":-420,"elapsed":421,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"2b5d8891-958b-4453-d698-372f5ecc6493"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Natural Language Processing',\n"," 'Language Processing is',\n"," 'Processing is the',\n"," 'is the way',\n"," 'the way to',\n"," 'way to go']"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["### Removing HTML Tags"],"metadata":{"id":"mPG_cCMiGCjP"}},{"cell_type":"code","source":["html = \"<!DOCTYPE html><html><body><h1>My First Heading</h1><p>My first paragraph.</p></body></html>\"\n","from bs4 import BeautifulSoup\n","\n","soup = BeautifulSoup(html)\n","text = soup.get_text()\n","print(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x5LKllfWGGrS","executionInfo":{"status":"ok","timestamp":1648950279151,"user_tz":-420,"elapsed":608,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"1e804d71-b2b8-4125-e2d3-dcb74120d234"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["My First HeadingMy first paragraph.\n"]}]},{"cell_type":"markdown","source":["### Building a basic vocabulary"],"metadata":{"id":"6EC2HjysGhsi"}},{"cell_type":"code","source":["s = \"Natural Language Processing is the way to go\"\n","tokens = set(s.split())\n","vocabulary = sorted(tokens)\n","vocabulary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lvd4xedwGkr8","executionInfo":{"status":"ok","timestamp":1648950400263,"user_tz":-420,"elapsed":28,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"c9195f09-fb14-4a54-a129-ed5ed5a27435"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Language', 'Natural', 'Processing', 'go', 'is', 'the', 'to', 'way']"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## All the basic preprocessing in one place\n","\n","Mari terpkan yang sudah dipelajari tadi. untuk detailnya simak dibawah ini...."],"metadata":{"id":"xKO6jQC9HWb-"}},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer \n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.stem.wordnet import WordNetLemmatizer\n","import pandas as pd\n","import re"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxJ5OQY5HxSp","executionInfo":{"status":"ok","timestamp":1648951035534,"user_tz":-420,"elapsed":435,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"f048cc93-1caa-4fc0-fd6f-6b152c4f0579"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/PBA/zomato_reviews.csv\")\n","df.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"tD7IsBoOH2pq","executionInfo":{"status":"ok","timestamp":1648951036013,"user_tz":-420,"elapsed":27,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"746efbfc-72e7-4e7d-92c1-4cad6b1a5141"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              Review sentiment\n","0  Virat Kohli did a great thing to open his rest...  positive\n","1  This place have some really heathy options to ...  positive\n","2  Aerocity is the most finest place in Delhi for...  positive"],"text/html":["\n","  <div id=\"df-f58b7c6c-0cf3-4d14-bdd8-199d2523d8f7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Virat Kohli did a great thing to open his rest...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>This place have some really heathy options to ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Aerocity is the most finest place in Delhi for...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f58b7c6c-0cf3-4d14-bdd8-199d2523d8f7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f58b7c6c-0cf3-4d14-bdd8-199d2523d8f7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f58b7c6c-0cf3-4d14-bdd8-199d2523d8f7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["corpus = pd.Series(df.Review.tolist()).astype(str)\n","corpus"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kIhUGornISei","executionInfo":{"status":"ok","timestamp":1648951036015,"user_tz":-420,"elapsed":23,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"c06299e8-2ee6-497e-8575-705c2abb9205"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       Virat Kohli did a great thing to open his rest...\n","1       This place have some really heathy options to ...\n","2       Aerocity is the most finest place in Delhi for...\n","3       Yesterday evening there was small team lunch ,...\n","4       I find aerocity to be the best place in delhi ...\n","                              ...                        \n","1591    || DESI LANE || So we were at alipore's most h...\n","1592    \"Desi Lane\" is one of the most trending place ...\n","1593    One of the cool and pocket pinch restaurant at...\n","1594    \"DESI LANE\" one of the best places in town and...\n","1595    Looking for good place for lunch but dont wann...\n","Length: 1596, dtype: object"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["### Text Cleaning (Removal of special characters/punctuations & case folding)"],"metadata":{"id":"SWZpdrwMIXRI"}},{"cell_type":"code","source":["def text_clean(corpus, keep_list):\n","    '''\n","    Purpose : Function to keep only alphabets, digits and certain words (punctuations, qmarks, tabs etc. removed)\n","    \n","    Input : Takes a text corpus, 'corpus' to be cleaned along with a list of words, 'keep_list', which have to be retained\n","            even after the cleaning process\n","    \n","    Output : Returns the cleaned text corpus\n","    \n","    '''\n","    cleaned_corpus = pd.Series()\n","    for row in corpus:\n","        qs = []\n","        for word in row.split():\n","            if word not in keep_list:\n","                p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n","                p1 = p1.lower()\n","                qs.append(p1)\n","            else : qs.append(word)\n","        cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n","    return cleaned_corpus"],"metadata":{"id":"sQhgFLc9IZYa","executionInfo":{"status":"ok","timestamp":1648951036608,"user_tz":-420,"elapsed":610,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["### Stopwords Removal"],"metadata":{"id":"uBdGBZhGIdg5"}},{"cell_type":"code","source":["def stopwords_removal(corpus):\n","    wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n","    stop = set(stopwords.words('english'))\n","    for word in wh_words:\n","        stop.remove(word)\n","    corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n","    return corpus"],"metadata":{"id":"Qz5AH3b8Ie7d","executionInfo":{"status":"ok","timestamp":1648951036608,"user_tz":-420,"elapsed":18,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Wx7DVenaJM34"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Lemmatization"],"metadata":{"id":"TYqhXI9FIi75"}},{"cell_type":"code","source":["def lemmatize(corpus):\n","    lem = WordNetLemmatizer()\n","    corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in corpus]\n","    return corpus"],"metadata":{"id":"sCuIE0GsIlOC","executionInfo":{"status":"ok","timestamp":1648951036609,"user_tz":-420,"elapsed":17,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["### Stemming"],"metadata":{"id":"XxB0PLzfIqKh"}},{"cell_type":"code","source":["def stem(corpus, stem_type = None):\n","    if stem_type == 'snowball':\n","        stemmer = SnowballStemmer(language = 'english')\n","        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n","    else :\n","        stemmer = PorterStemmer()\n","        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n","    return corpus"],"metadata":{"id":"ooYiNYXnIsbI","executionInfo":{"status":"ok","timestamp":1648951036609,"user_tz":-420,"elapsed":14,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def preprocess(corpus, keep_list, cleaning = True, stemming = False, stem_type = None, lemmatization = False, remove_stopwords = True):\n","    '''\n","    Purpose : Function to perform all pre-processing tasks (cleaning, stemming, lemmatization, stopwords removal etc.)\n","    \n","    Input : \n","    'corpus' - Text corpus on which pre-processing tasks will be performed\n","    'keep_list' - List of words to be retained during cleaning process\n","    'cleaning', 'stemming', 'lemmatization', 'remove_stopwords' - Boolean variables indicating whether a particular task should \n","                                                                  be performed or not\n","    'stem_type' - Choose between Porter stemmer or Snowball(Porter2) stemmer. Default is \"None\", which corresponds to Porter\n","                  Stemmer. 'snowball' corresponds to Snowball Stemmer\n","    \n","    Note : Either stemming or lemmatization should be used. There's no benefit of using both of them together\n","    \n","    Output : Returns the processed text corpus\n","    \n","    '''\n","    \n","    if cleaning == True:\n","        corpus = text_clean(corpus, keep_list)\n","    \n","    if remove_stopwords == True:\n","        corpus = stopwords_removal(corpus)\n","    else :\n","        corpus = [[x for x in x.split()] for x in corpus]\n","    \n","    if lemmatization == True:\n","        corpus = lemmatize(corpus)\n","        \n","        \n","    if stemming == True:\n","        corpus = stem(corpus, stem_type)\n","    \n","    corpus = [' '.join(x) for x in corpus]        \n","\n","    return corpus"],"metadata":{"id":"ZIk45c6ZIxC0","executionInfo":{"status":"ok","timestamp":1648951036611,"user_tz":-420,"elapsed":14,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["common_dot_words = ['U.S.A', 'Mr.', 'Mrs.', 'D.C.']"],"metadata":{"id":"j-30vepNI0Ak","executionInfo":{"status":"ok","timestamp":1648951036613,"user_tz":-420,"elapsed":14,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Preprocessing with Lemmatization here\n","corpus_with_lemmatization = preprocess(corpus, keep_list = common_dot_words, stemming = False, stem_type = None, lemmatization = True, remove_stopwords = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOAqMFQwI3Nq","executionInfo":{"status":"ok","timestamp":1648951039777,"user_tz":-420,"elapsed":3176,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"5b97c767-877b-4111-c825-e0f07fefe6e9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n","  # This is added back by InteractiveShellApp.init_path()\n"]}]},{"cell_type":"code","source":["# Preprocessing with Stemming here here\n","corpus_with_stemming = preprocess(corpus, keep_list = common_dot_words, stemming = True, stem_type = \"snowball\", lemmatization = False, remove_stopwords = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nq9lM1FtI5jg","executionInfo":{"status":"ok","timestamp":1648951041366,"user_tz":-420,"elapsed":1597,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"075af55a-2eca-4026-f819-d803ca2b4c47"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n","  # This is added back by InteractiveShellApp.init_path()\n"]}]},{"cell_type":"markdown","source":["### Output"],"metadata":{"id":"dvNKiithJN8X"}},{"cell_type":"markdown","source":["#### Original"],"metadata":{"id":"YprqeKEDJStT"}},{"cell_type":"code","source":[""],"metadata":{"id":"LhS3tuy3Jdli","executionInfo":{"status":"ok","timestamp":1648951194401,"user_tz":-420,"elapsed":867,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["print(\"Original string: \", corpus[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yl671fT6JYSr","executionInfo":{"status":"ok","timestamp":1648951195693,"user_tz":-420,"elapsed":12,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"b4e85481-88ab-40bc-bf72-fd2cf95085a2"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Original string:  Virat Kohli did a great thing to open his restaurant in an exquisite place of Delhi. Wide range of food with lots and lots of options on drinks. Courteous staff with a quick response on anything.\n"]}]},{"cell_type":"markdown","source":["#### Lemmatization"],"metadata":{"id":"TEzkQUwrJbiA"}},{"cell_type":"code","source":["print(\"String after lemmatiization: \", corpus_with_lemmatization[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cy4rbtciJfCo","executionInfo":{"status":"ok","timestamp":1648951195694,"user_tz":-420,"elapsed":12,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"ed5cf5c5-e333-4e80-f159-61a56f228d1c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["String after lemmatiization:  virat kohli great thing open restaurant exquisite place delhi wide range food lot lot options drink courteous staff quick response anything\n"]}]},{"cell_type":"markdown","source":["#### Stemming"],"metadata":{"id":"kbmvMCmUJjRp"}},{"cell_type":"code","source":["print(\"String after stemming: \", corpus_with_stemming[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmpVoH95JlRo","executionInfo":{"status":"ok","timestamp":1648951195694,"user_tz":-420,"elapsed":8,"user":{"displayName":"RamandaAA Mahasiswa","userId":"07619045368833697713"}},"outputId":"05aea2d6-dcdd-4945-e94d-0d7204a7e931"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["String after stemming:  virat koh great thing open restaur exquisit place delhi wide rang food lot lot option drink courteous staff quick respons anyth\n"]}]}]}